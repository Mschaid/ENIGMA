{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Validation and plotting of full_sequence_stacked_01\"\n",
    "author: \"Mike Schaid\"\n",
    "date: \"2023-08-07\"\n",
    "theme: cosmo\n",
    "format: \n",
    "  html: \n",
    "    monobackgroundcolor: '#f1f1f101'\n",
    "    code-fold: true\n",
    "    code-block-border-left: true\n",
    "    code-block-bg: \"#0000\"\n",
    "    code-block-border-left: \"#999999\"\n",
    "    highlight-style: a11y\n",
    "    embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec # for subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from src.data_processing.pipelines.LSTMPipe import LSTMPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/projects/p31961/gaby_data/aggregated_data/data_pipeline_full_dataset/datasets/full_dataset.parquet.gzip'\n",
    "# MODEL_PATH = \"/projects/p31961/ENIGMA/results/experiments/dopamine_full_sequence_stacked_lstm_01/models/dopamine_full_sequence_stacked_lstm_01\"\n",
    "\n",
    "# local\n",
    "DATA_PATH = '/Users/mds8301/iterm_data_storage/raw_data_raw_data.parquet.gzip'\n",
    "MODEL_PATH = '/Users/mds8301/Devlopment/enigma/results/experiments/full_sequence_stacked_lstm_01/models/full_sequence_stacked_lstm_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LSTMPipe(DATA_PATH)\n",
    "processor.read_raw_data()\n",
    "processor.raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mds8301/Devlopment/enigma/results/experiments/full_sequence_stacked_lstm_01/subjects.json', 'r') as f:\n",
    "    subjects = json.load(f)\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = subjects['training']\n",
    "dev_subjects = subjects['dev']\n",
    "test_subjects = subjects['test']\n",
    "\n",
    "training_query = ' or '.join([f\"mouse_id=={subject}\" for subject in training_subjects])\n",
    "dev_query = ' or '.join([f\"mouse_id=={subject}\" for subject in dev_subjects])\n",
    "test_query = ' or '.join([f\"mouse_id=={subject}\" for subject in test_subjects])\n",
    "\n",
    "def split_by_subjects_query(subjects):\n",
    "    query = ' or '.join([f\"mouse_id=={subject}\" for subject in subjects])\n",
    "    x, y = processor.raw_data.query(query).drop(columns =\"signal\"), processor.raw_data.query(query)['signal']\n",
    "    return x, y\n",
    "\n",
    "processor.X_train, processor.y_train = split_by_subjects_query(training_subjects)\n",
    "processor.X_dev, processor.y_dev = split_by_subjects_query(dev_subjects)\n",
    "processor.X_test, processor.y_test = split_by_subjects_query(test_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data_processing.pipelines.LSTMPipe.LSTMPipe at 0x2a3da2f50>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.transorm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mds8301/anaconda3/envs/enigma/lib/python3.11/site-packages/keras/src/layers/core/lambda_layer.py:327: UserWarning: src.models.experimental_dropout_StackedLSTM is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\n",
    "        'mae', 'mse', 'mape', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"stacked_lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Lambda_1 (Lambda)           multiple                  0         \n",
      "                                                                 \n",
      " LSTM_1 (LSTM)               multiple                  5472      \n",
      "                                                                 \n",
      " Dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " LSTM_2 (LSTM)               multiple                  10512     \n",
      "                                                                 \n",
      " Dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " Dense_output (Dense)        multiple                  37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16021 (62.58 KB)\n",
      "Trainable params: 16021 (62.58 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37556/37556 [==============================] - 120s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_signal = model.predict(processor.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_raw, y_test_raw = split_by_subjects_query(test_subjects)\n",
    "full_test_set = (x_test_raw\n",
    "                 .assign(\n",
    "                     true_signal=y_test_raw,\n",
    "                     predicted_signal = predicted_signal\n",
    "                     )\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1201792, 13)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mouse_id                  0\n",
       "day                       0\n",
       "event                     0\n",
       "sensor                    0\n",
       "time                      0\n",
       "trial                     0\n",
       "action                  458\n",
       "latency                   0\n",
       "sex                       0\n",
       "learning_phase            0\n",
       "trial_count               0\n",
       "true_signal             443\n",
       "predicted_signal    1201792\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse_id</th>\n",
       "      <th>day</th>\n",
       "      <th>event</th>\n",
       "      <th>sensor</th>\n",
       "      <th>time</th>\n",
       "      <th>trial</th>\n",
       "      <th>action</th>\n",
       "      <th>latency</th>\n",
       "      <th>sex</th>\n",
       "      <th>learning_phase</th>\n",
       "      <th>trial_count</th>\n",
       "      <th>true_signal</th>\n",
       "      <th>predicted_signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>cue</td>\n",
       "      <td>D2</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>escape</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.155359</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>cue</td>\n",
       "      <td>D2</td>\n",
       "      <td>-24.901531</td>\n",
       "      <td>0</td>\n",
       "      <td>escape</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.420553</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>cue</td>\n",
       "      <td>D2</td>\n",
       "      <td>-24.803064</td>\n",
       "      <td>0</td>\n",
       "      <td>escape</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>-1.592294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>cue</td>\n",
       "      <td>D2</td>\n",
       "      <td>-24.704596</td>\n",
       "      <td>0</td>\n",
       "      <td>escape</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>-1.268734</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>cue</td>\n",
       "      <td>D2</td>\n",
       "      <td>-24.606127</td>\n",
       "      <td>0</td>\n",
       "      <td>escape</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>-0.210176</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848197</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>escape</td>\n",
       "      <td>DA</td>\n",
       "      <td>19.606127</td>\n",
       "      <td>11</td>\n",
       "      <td>avoid</td>\n",
       "      <td>5.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.010664</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848198</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>escape</td>\n",
       "      <td>DA</td>\n",
       "      <td>19.704596</td>\n",
       "      <td>11</td>\n",
       "      <td>avoid</td>\n",
       "      <td>5.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.472312</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848199</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>escape</td>\n",
       "      <td>DA</td>\n",
       "      <td>19.803064</td>\n",
       "      <td>11</td>\n",
       "      <td>avoid</td>\n",
       "      <td>5.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848200</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>escape</td>\n",
       "      <td>DA</td>\n",
       "      <td>19.901531</td>\n",
       "      <td>11</td>\n",
       "      <td>avoid</td>\n",
       "      <td>5.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.525126</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5848201</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>escape</td>\n",
       "      <td>DA</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>avoid</td>\n",
       "      <td>5.5</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.512115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201792 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mouse_id  day   event sensor       time  trial  action  latency sex  \\\n",
       "0              12    5     cue     D2 -25.000000      0  escape      0.0   F   \n",
       "1              12    5     cue     D2 -24.901531      0  escape      0.0   F   \n",
       "2              12    5     cue     D2 -24.803064      0  escape      0.0   F   \n",
       "3              12    5     cue     D2 -24.704596      0  escape      0.0   F   \n",
       "4              12    5     cue     D2 -24.606127      0  escape      0.0   F   \n",
       "...           ...  ...     ...    ...        ...    ...     ...      ...  ..   \n",
       "5848197         5    4  escape     DA  19.606127     11   avoid      5.5   M   \n",
       "5848198         5    4  escape     DA  19.704596     11   avoid      5.5   M   \n",
       "5848199         5    4  escape     DA  19.803064     11   avoid      5.5   M   \n",
       "5848200         5    4  escape     DA  19.901531     11   avoid      5.5   M   \n",
       "5848201         5    4  escape     DA  20.000000     11   avoid      5.5   M   \n",
       "\n",
       "         learning_phase  trial_count  true_signal  predicted_signal  \n",
       "0                     0          115    -0.155359               NaN  \n",
       "1                     0          115    -0.420553               NaN  \n",
       "2                     0          115    -1.592294               NaN  \n",
       "3                     0          115    -1.268734               NaN  \n",
       "4                     0          115    -0.210176               NaN  \n",
       "...                 ...          ...          ...               ...  \n",
       "5848197               1           98    -0.010664               NaN  \n",
       "5848198               1           98     0.472312               NaN  \n",
       "5848199               1           98     0.005370               NaN  \n",
       "5848200               1           98    -0.525126               NaN  \n",
       "5848201               1           98    -0.512115               NaN  \n",
       "\n",
       "[1201792 rows x 13 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.data_processing.pipelines.LSTMPipe.LSTMPipe at 0x4e35b6cd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processor_pipe = (LSTMPipe(DATA_PATH)\n",
    ".read_raw_data(sort_by=['mouse_id','sensor','event', 'trial_count']))\n",
    "processor.raw_data = processor_pipe.raw_data[::10000]\n",
    "(processor_pipe.split_data(processed_data = False, \n",
    "            test_size=0.3,\n",
    "            test_dev_size=0.5, \n",
    "            split_group = \"mouse_id\", \n",
    "            stratify_group = \"sex\", \n",
    "            target='signal', \n",
    "            save_subject_ids=False)\n",
    ".transorm_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
      "Epoch 1/5\n",
      "  1725/116018 [..............................] - ETA: 25:03 - loss: nan - mae: nan - mse: nan - mape: nan - cosine_similarity: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 25\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# call backs\u001b[39;00m\n\u001b[1;32m     22\u001b[0m learning_rate_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mLearningRateScheduler(\n\u001b[1;32m     23\u001b[0m     lr_schedular, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m model\u001b[39m.\u001b[39mfit(processor\u001b[39m.\u001b[39mX_train,\n\u001b[1;32m     26\u001b[0m             processor\u001b[39m.\u001b[39my_train,\n\u001b[1;32m     27\u001b[0m             epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     28\u001b[0m             validation_data\u001b[39m=\u001b[39m(processor\u001b[39m.\u001b[39mX_dev, processor\u001b[39m.\u001b[39my_dev),\n\u001b[1;32m     29\u001b[0m             callbacks\u001b[39m=\u001b[39m[learning_rate_callback]\n\u001b[1;32m     30\u001b[0m             )\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mevaluate(processor\u001b[39m.\u001b[39mX_test, processor\u001b[39m.\u001b[39my_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function(\u001b[39m*\u001b[39margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/enigma/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.models.experimental_dropout_StackedLSTM import StackedLSTM\n",
    "def lr_schedular(epoch, lr):\n",
    "        if epoch < 10:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "model = StackedLSTM(\n",
    "    sequence_length=processor.raw_data['time'].nunique(),\n",
    "    num_features=processor.X_train.shape[1],\n",
    "    lstm_units=processor.X_train.shape[1] * 2\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\n",
    "    'mae', 'mse', 'mape', 'cosine_similarity'])\n",
    "\n",
    "# call backs\n",
    "\n",
    "\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lr_schedular, verbose=1)\n",
    "\n",
    "model.fit(processor.X_train,\n",
    "            processor.y_train,\n",
    "            epochs=5,\n",
    "            validation_data=(processor.X_dev, processor.y_dev),\n",
    "            callbacks=[learning_rate_callback]\n",
    "            )\n",
    "\n",
    "\n",
    "model.evaluate(processor.X_test, processor.y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = avoid, x = 'time', y = 'signal', hue = 'signal_type')\n",
    "# sns.lineplot(data = query, x = 'time', y = 'predicted_signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(avoid, row = 'day', col = \"learning_phase\")\n",
    "facet.map_dataframe(sns.lineplot, x = 'time', y = 'signal', hue = 'signal_type', hue_order = [\"true_signal\", \"predicted_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_3 = avoid.query(\"mouse_id_3==1 & trial_count < 10\")\n",
    "mouse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = mouse_3.query(\"trial_count==9\"), x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalulation = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, evalulation):\n",
    "    print(f'{name}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_testing_subjects(subjects, df):\n",
    "    \n",
    "    full_query = ''\n",
    "    for mouse in subjects:\n",
    "        query =f\"{mouse} == 1\"\n",
    "        if full_query == '':\n",
    "            full_query = query\n",
    "        else:\n",
    "            full_query += f\" or {query}\" \n",
    "        \n",
    "    return df.query(full_query)\n",
    "\n",
    "train_set = query_testing_subjects(subjects_by_category['training'], train_processor.data)\n",
    "X_train, y_train = train_set.drop(columns = 'signal'), train_set['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_signal = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_set = (X_train\n",
    "                 .assign(\n",
    "                     true_signal=y_train,\n",
    "                     predicted_signal = predicted_signal\n",
    "                     )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avoid = (full_train_set\n",
    "         .query(\"action_avoid==1 & event_cue==1\")\n",
    "         .melt(id_vars = full_test_set.drop(columns = ['predicted_signal', 'true_signal']).columns, value_vars= ['predicted_signal', 'true_signal'], value_name = \"signal\", var_name = 'signal_type'))\n",
    "train_avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data = train_avoid, x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train_avoid, row = 'day', col = \"learning_phase\")\n",
    "facet.map_dataframe(sns.lineplot, x = 'time', y = 'signal', hue = 'signal_type', hue_order = [\"true_signal\", \"predicted_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_id_1_train  = train_avoid.query(\"mouse_id_1==1 & trial_count < 20\")\n",
    "sns.lineplot(data = mouse_id_1_train.query(\"trial_count==17\"), x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "given the training performance data, I think this model is still overrfitting. It looks a little better, but validation loss is still increasing. I am going to expand on this and include a standard learning rate schedular in experiment 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
