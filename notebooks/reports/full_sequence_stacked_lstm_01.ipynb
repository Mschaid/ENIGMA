{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Validation and plotting of full_sequence_stacked_01\"\n",
    "author: \"Mike Schaid\"\n",
    "date: \"2023-08-07\"\n",
    "theme: cosmo\n",
    "format: \n",
    "  html: \n",
    "    monobackgroundcolor: '#f1f1f101'\n",
    "    code-fold: true\n",
    "    code-block-border-left: true\n",
    "    code-block-bg: \"#0000\"\n",
    "    code-block-border-left: \"#999999\"\n",
    "    highlight-style: a11y\n",
    "    embed-resources: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec # for subplots\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "from src.data_processing.pipelines.LSTMPipe import LSTMPipe\n",
    "from src.models.experimental_dropout_StackedLSTM import StackedLSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# print gpus available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/projects/p31961/gaby_data/aggregated_data/raw_data/datasets/raw_data_raw_data.parquet.gzip'\n",
    "# MODEL_PATH = \"/projects/p31961/ENIGMA/results/experiments/dopamine_full_sequence_stacked_lstm_01/models/dopamine_full_sequence_stacked_lstm_01\"\n",
    "\n",
    "# locald\n",
    "# DATA_PATH = '/Users/mds8301/iterm_data_storage/raw_data_raw_data.parquet.gzip'\n",
    "# MODEL_PATH = '/Users/mds8301/Development/enigma/results/experiments/full_sequence_stacked_lstm_01/models/full_sequence_stacked_lstm_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "processor = LSTMPipe(DATA_PATH)\n",
    "processor.read_raw_data()\n",
    "processor.raw_data=processor.raw_data[::1000]\n",
    "processor.raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('/projects/p31961/ENIGMA/results/experiments/full_sequence_stacked_lstm_01/subjects.json', 'r') as f:\n",
    "    subjects = json.load(f)\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "training_subjects = subjects['training']\n",
    "dev_subjects = subjects['dev']\n",
    "test_subjects = subjects['test']\n",
    "\n",
    "training_query = ' or '.join([f\"mouse_id=={subject}\" for subject in training_subjects])\n",
    "dev_query = ' or '.join([f\"mouse_id=={subject}\" for subject in dev_subjects])\n",
    "test_query = ' or '.join([f\"mouse_id=={subject}\" for subject in test_subjects])\n",
    "\n",
    "def split_by_subjects_query(subjects):\n",
    "    query = ' or '.join([f\"mouse_id=={subject}\" for subject in subjects])\n",
    "    x, y = processor.raw_data.query(query).drop(columns =\"signal\"), processor.raw_data.query(query)['signal']\n",
    "    return x, y\n",
    "\n",
    "processor.X_train, processor.y_train = split_by_subjects_query(training_subjects)\n",
    "processor.X_dev, processor.y_dev = split_by_subjects_query(dev_subjects)\n",
    "processor.X_test, processor.y_test = split_by_subjects_query(test_subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "processor.transorm_data()\n",
    "processor.X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def lr_schedular(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(1.)/epoch\n",
    "epochs = range(1,400,1)\n",
    "lrs = np.array([lr_schedular(e, 0.001) for e in epochs])\n",
    "plt.plot(epochs, lrs)\n",
    "# plot loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# tf tensor\n",
    "X_train = tf.convert_to_tensor(processor.X_train)\n",
    "y_train = tf.convert_to_tensor(processor.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = StackedLSTM(\n",
    "    sequence_length=processor.raw_data['time'].nunique(),\n",
    "    num_features=processor.X_train.shape[1],\n",
    "    lstm_units=processor.X_train.shape[1] * 2\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\n",
    "    'mae', 'mse', 'mape', 'cosine_similarity'])\n",
    "\n",
    "\n",
    "\n",
    "# learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "#     lr_schedular, verbose=1)\n",
    "\n",
    "model.fit(processor.X_train,\n",
    "            processor.y_train,\n",
    "            epochs=5,\n",
    "            validation_data=(processor.X_dev, processor.y_dev)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse', metrics=[\n",
    "#         'mae', 'mse', 'mape', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predicted_signal = model.predict(processor.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "x_test_raw, y_test_raw = split_by_subjects_query(test_subjects)\n",
    "full_test_set = (x_test_raw\n",
    "                 .assign(\n",
    "                     true_signal=y_test_raw,\n",
    "                     predicted_signal = predicted_signal\n",
    "                     )\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "full_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "full_test_set.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "full_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "processor_pipe = (LSTMPipe(DATA_PATH)\n",
    ".read_raw_data(sort_by=['mouse_id','sensor','event', 'trial_count']))\n",
    "processor.raw_data = processor_pipe.raw_data[::10000]\n",
    "(processor_pipe.split_data(processed_data = False, \n",
    "            test_size=0.3,\n",
    "            test_dev_size=0.5, \n",
    "            split_group = \"mouse_id\", \n",
    "            stratify_group = \"sex\", \n",
    "            target='signal', \n",
    "            save_subject_ids=False)\n",
    ".transorm_data()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from src.models.experimental_dropout_StackedLSTM import StackedLSTM\n",
    "def lr_schedular(epoch, lr):\n",
    "        if epoch < 10:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "model = StackedLSTM(\n",
    "    sequence_length=processor.raw_data['time'].nunique(),\n",
    "    num_features=processor.X_train.shape[1],\n",
    "    lstm_units=processor.X_train.shape[1] * 2\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=[\n",
    "    'mae', 'mse', 'mape', 'cosine_similarity'])\n",
    "\n",
    "# call backs\n",
    "\n",
    "\n",
    "learning_rate_callback = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lr_schedular, verbose=1)\n",
    "\n",
    "model.fit(processor.X_train,\n",
    "            processor.y_train,\n",
    "            epochs=5,\n",
    "            validation_data=(processor.X_dev, processor.y_dev),\n",
    "            callbacks=[learning_rate_callback]\n",
    "            )\n",
    "\n",
    "\n",
    "model.evaluate(processor.X_test, processor.y_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = avoid, x = 'time', y = 'signal', hue = 'signal_type')\n",
    "# sns.lineplot(data = query, x = 'time', y = 'predicted_signal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(avoid, row = 'day', col = \"learning_phase\")\n",
    "facet.map_dataframe(sns.lineplot, x = 'time', y = 'signal', hue = 'signal_type', hue_order = [\"true_signal\", \"predicted_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mouse_3 = avoid.query(\"mouse_id_3==1 & trial_count < 10\")\n",
    "mouse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = mouse_3.query(\"trial_count==9\"), x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "evalulation = model.evaluate(X_test, y_test)\n",
    "for name, value in zip(model.metrics_names, evalulation):\n",
    "    print(f'{name}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def query_testing_subjects(subjects, df):\n",
    "    \n",
    "    full_query = ''\n",
    "    for mouse in subjects:\n",
    "        query =f\"{mouse} == 1\"\n",
    "        if full_query == '':\n",
    "            full_query = query\n",
    "        else:\n",
    "            full_query += f\" or {query}\" \n",
    "        \n",
    "    return df.query(full_query)\n",
    "\n",
    "train_set = query_testing_subjects(subjects_by_category['training'], train_processor.data)\n",
    "X_train, y_train = train_set.drop(columns = 'signal'), train_set['signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predicted_signal = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "full_train_set = (X_train\n",
    "                 .assign(\n",
    "                     true_signal=y_train,\n",
    "                     predicted_signal = predicted_signal\n",
    "                     )\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_avoid = (full_train_set\n",
    "         .query(\"action_avoid==1 & event_cue==1\")\n",
    "         .melt(id_vars = full_test_set.drop(columns = ['predicted_signal', 'true_signal']).columns, value_vars= ['predicted_signal', 'true_signal'], value_name = \"signal\", var_name = 'signal_type'))\n",
    "train_avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = train_avoid, x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train_avoid, row = 'day', col = \"learning_phase\")\n",
    "facet.map_dataframe(sns.lineplot, x = 'time', y = 'signal', hue = 'signal_type', hue_order = [\"true_signal\", \"predicted_signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "mouse_id_1_train  = train_avoid.query(\"mouse_id_1==1 & trial_count < 20\")\n",
    "sns.lineplot(data = mouse_id_1_train.query(\"trial_count==17\"), x = 'time', y = 'signal', hue = 'signal_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "given the training performance data, I think this model is still overrfitting. It looks a little better, but validation loss is still increasing. I am going to expand on this and include a standard learning rate schedular in experiment 3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigma_xgbuser",
   "language": "python",
   "name": "enigma_xgbuser"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
