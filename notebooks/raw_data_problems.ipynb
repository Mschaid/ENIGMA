{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: \n",
    "I ended up finidng issues in the data where downsampling was down incorrectly, this notebook is only saved in the interm. LSTM 01 and 02 are invalid and have been deleted. This notebook is only here for reference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial exploration of full training LSTM simple 01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.modeling.prototyping.lstm_protype_simple import validated_tf\n",
    "from src.modeling.prototyping.lstm_simple_initial_training import build_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_tf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTSM_1_PATH = '/projects/p31961/dopamine_modeling/results/models/lstm_simple_initial_training_with_downsampling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsm = tf.keras.models.load_model(LTSM_1_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltsm.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data was downsampled during preprocessing selecting every 100th data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/projects/p31961/gaby_data/aggregated_data/data_pipeline/datasets'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reformating and data aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(df, true_signal, infered_signal):\n",
    "    cols_to_group = ['day', 'time', 'event_cue', 'event_shock', 'sensor_D1', 'sensor_D2', 'sensor_DA']\n",
    "    agg_diict = {'true_signal': ['mean', 'sem'],\n",
    "             'predicted_signal': ['mean', 'sem']\n",
    "             }\n",
    "    def flatten_df(df):\n",
    "        df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    def strip_cols(df):\n",
    "        df.columns = [col.rstrip('_') for col in df.columns]\n",
    "        return df\n",
    "    return(\n",
    "        df.assign(\n",
    "            true_signal=true_signal, \n",
    "            predicted_signal=infered_signal)\n",
    "        .reset_index(drop=True)\n",
    "        .groupby(by = cols_to_group, as_index = False).agg(agg_diict)\n",
    "        .pipe(flatten_df)\n",
    "        .pipe(strip_cols)\n",
    "        .drop(columns = 'index')\n",
    "\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "the data is clearly incorrect. I think data is downsampled too much, I have preprocessed the data gain sampling every 10th data point and retrained to LSTM simple 02"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of LSTM_02_simple retran with smaller downsample (25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'day6_cue_da' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     sns\u001b[39m.\u001b[39mlineplot(data\u001b[39m=\u001b[39mday6_cue_da, x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mfill_between(day6_cue_da[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m], day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_sem\u001b[39m\u001b[39m'\u001b[39m], day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_sem\u001b[39m\u001b[39m'\u001b[39m], alpha\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plot_signal(\u001b[39m'\u001b[39m\u001b[39mtrue_signal\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plot_signal(\u001b[39m'\u001b[39m\u001b[39mpredicted_signal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[111], line 2\u001b[0m, in \u001b[0;36mplot_signal\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_signal\u001b[39m(y):\n\u001b[0;32m----> 2\u001b[0m     sns\u001b[39m.\u001b[39mlineplot(data\u001b[39m=\u001b[39mday6_cue_da, x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      3\u001b[0m     plt\u001b[39m.\u001b[39mfill_between(day6_cue_da[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m], day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_sem\u001b[39m\u001b[39m'\u001b[39m], day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m day6_cue_da[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m_sem\u001b[39m\u001b[39m'\u001b[39m], alpha\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'day6_cue_da' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_signal(y):\n",
    "    sns.lineplot(data=day6_cue_da, x='time', y=f'{y}_mean', color='black', linewidth=0.5)\n",
    "    plt.fill_between(day6_cue_da['time'], day6_cue_da[f'{y}_mean'] - day6_cue_da[f'{y}_sem'], day6_cue_da[f'{y}_mean'] + day6_cue_da[f'{y}_sem'], alpha=.2, color='black')\n",
    "plot_signal('true_signal')\n",
    "plot_signal('predicted_signal')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is wrong with the data?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = '/projects/p31961/gaby_data/aggregated_data/aggregated_data.parquet.gzp'\n",
    "raw_data = pd.read_parquet(RAW_PATH)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds25 = raw_data[::100]\n",
    "raw_ds25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    def flatten_df(df):\n",
    "        df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    def strip_cols(df):\n",
    "        df.columns = [col.rstrip('_') for col in df.columns]\n",
    "        return df\n",
    "        \n",
    "    group_by = ['time', 'sensor', 'trial', 'mouse_id', 'day', 'event']\n",
    "    agg_dict = {'signal': ['mean']}\n",
    "\n",
    "    grouped= (\n",
    "        df.groupby(by=group_by, as_index=False).agg(agg_dict)\n",
    "        .pipe(flatten_df)\n",
    "        .pipe(strip_cols)\n",
    "        .drop(columns = 'index')\n",
    "        .sort_values(by = [col for col in group_by if col != 'time'])\n",
    "        [::100]\n",
    "    )\n",
    "    return (grouped\n",
    "            # .query('day==1 & event==\"cue\" & sensor==\"DA\"')\n",
    "            # .groupby(by = ['time'], as_index=True).agg({'signal_mean': ['mean', 'sem']})\n",
    "            # .pipe(flatten_df)\n",
    "            # .pipe(strip_cols)\n",
    "    )\n",
    "\n",
    "d1_cue_da_ds = filter_data(raw_ds25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filter_ds = filter_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filter_ds.query(\"mouse_id=='310_907' & event== 'cue' & sensor=='DA' & day==3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.query(\"mouse_id=='310_907' & event== 'cue' & sensor=='DA' & day==3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_vals = raw_data[raw_data.isna().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values from signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by = ['mouse_id', 'trial',  'day', 'event', 'sensor']\n",
    "nan_vals.groupby(by = group_by, as_index=False).count().drop(columns = ['time', 'signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = f'/projects/p31961/gaby_data/aggregated_data/aggregated_data'\n",
    "new_path = os.path.join(path_to_save, 'aggregated_data_test_downsample')\n",
    "raw_filter_ds.to_parquet(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_cue_da_ds.sort_values(by=['sensor', 'trial', 'mouse_id', 'day', 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_cue_da_raw = filter_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_cue_da_raw\n",
    "# correct_down_sample = d1_cue_da_raw[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, title):\n",
    "    sns.lineplot(data=df, x='time', y='signal_mean_mean',linewidth=0.2)\n",
    "    # change y axsis to be -2 to 2\n",
    "    plt.fill_between(df['time'], df['signal_mean_mean'] - df['signal_mean_sem'], df['signal_mean_mean'] + df['signal_mean_sem'], alpha=.2, color='black')\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title(title)\n",
    "    \n",
    "# plot_data(df = d1_cue_da_raw, title='raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `signal_mean_mean` for parameter `y`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_data(df \u001b[39m=\u001b[39m d1_cue_da_ds, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdownsampled data\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[112], line 2\u001b[0m, in \u001b[0;36mplot_data\u001b[0;34m(df, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_data\u001b[39m(df, title):\n\u001b[0;32m----> 2\u001b[0m     sns\u001b[39m.\u001b[39mlineplot(data\u001b[39m=\u001b[39mdf, x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msignal_mean_mean\u001b[39m\u001b[39m'\u001b[39m,linewidth\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[39m# change y axsis to be -2 to 2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mfill_between(df[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39msignal_mean_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msignal_mean_sem\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39msignal_mean_mean\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39msignal_mean_sem\u001b[39m\u001b[39m'\u001b[39m], alpha\u001b[39m=\u001b[39m\u001b[39m.2\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dope/lib/python3.11/site-packages/seaborn/relational.py:618\u001b[0m, in \u001b[0;36mlineplot\u001b[0;34m(data, x, y, hue, size, style, units, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m errorbar \u001b[39m=\u001b[39m _deprecate_ci(errorbar, ci)\n\u001b[1;32m    617\u001b[0m variables \u001b[39m=\u001b[39m _LinePlotter\u001b[39m.\u001b[39mget_semantics(\u001b[39mlocals\u001b[39m())\n\u001b[0;32m--> 618\u001b[0m p \u001b[39m=\u001b[39m _LinePlotter(\n\u001b[1;32m    619\u001b[0m     data\u001b[39m=\u001b[39mdata, variables\u001b[39m=\u001b[39mvariables,\n\u001b[1;32m    620\u001b[0m     estimator\u001b[39m=\u001b[39mestimator, n_boot\u001b[39m=\u001b[39mn_boot, seed\u001b[39m=\u001b[39mseed, errorbar\u001b[39m=\u001b[39merrorbar,\n\u001b[1;32m    621\u001b[0m     sort\u001b[39m=\u001b[39msort, orient\u001b[39m=\u001b[39morient, err_style\u001b[39m=\u001b[39merr_style, err_kws\u001b[39m=\u001b[39merr_kws,\n\u001b[1;32m    622\u001b[0m     legend\u001b[39m=\u001b[39mlegend,\n\u001b[1;32m    623\u001b[0m )\n\u001b[1;32m    625\u001b[0m p\u001b[39m.\u001b[39mmap_hue(palette\u001b[39m=\u001b[39mpalette, order\u001b[39m=\u001b[39mhue_order, norm\u001b[39m=\u001b[39mhue_norm)\n\u001b[1;32m    626\u001b[0m p\u001b[39m.\u001b[39mmap_size(sizes\u001b[39m=\u001b[39msizes, order\u001b[39m=\u001b[39msize_order, norm\u001b[39m=\u001b[39msize_norm)\n",
      "File \u001b[0;32m~/.conda/envs/dope/lib/python3.11/site-packages/seaborn/relational.py:365\u001b[0m, in \u001b[0;36m_LinePlotter.__init__\u001b[0;34m(self, data, variables, estimator, n_boot, seed, errorbar, sort, orient, err_style, err_kws, legend)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    352\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m,\n\u001b[1;32m    353\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, variables\u001b[39m=\u001b[39m{},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# the kind of plot to draw, but for the time being we need to set\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# this information so the SizeMapping can use it\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_size_range \u001b[39m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         np\u001b[39m.\u001b[39mr_[\u001b[39m.5\u001b[39m, \u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mlines.linewidth\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    363\u001b[0m     )\n\u001b[0;32m--> 365\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(data\u001b[39m=\u001b[39mdata, variables\u001b[39m=\u001b[39mvariables)\n\u001b[1;32m    367\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator \u001b[39m=\u001b[39m estimator\n\u001b[1;32m    368\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrorbar \u001b[39m=\u001b[39m errorbar\n",
      "File \u001b[0;32m~/.conda/envs/dope/lib/python3.11/site-packages/seaborn/_oldcore.py:640\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[39m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[39m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_var_ordered \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mFalse\u001b[39;00m}  \u001b[39m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massign_variables(data, variables)\n\u001b[1;32m    642\u001b[0m \u001b[39mfor\u001b[39;00m var, \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_semantic_mappings\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m     \u001b[39m# Create the mapping function\u001b[39;00m\n\u001b[1;32m    645\u001b[0m     map_func \u001b[39m=\u001b[39m partial(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmap, plotter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/dope/lib/python3.11/site-packages/seaborn/_oldcore.py:701\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlong\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 701\u001b[0m     plot_data, variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assign_variables_longform(\n\u001b[1;32m    702\u001b[0m         data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mvariables,\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot_data \u001b[39m=\u001b[39m plot_data\n\u001b[1;32m    706\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m variables\n",
      "File \u001b[0;32m~/.conda/envs/dope/lib/python3.11/site-packages/seaborn/_oldcore.py:938\u001b[0m, in \u001b[0;36mVectorPlotter._assign_variables_longform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(val, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[1;32m    934\u001b[0m \n\u001b[1;32m    935\u001b[0m     \u001b[39m# This looks like a column name but we don't know what it means!\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not interpret value `\u001b[39m\u001b[39m{\u001b[39;00mval\u001b[39m}\u001b[39;00m\u001b[39m` for parameter `\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[1;32m    940\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m     \u001b[39m# Otherwise, assume the value is itself data\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \n\u001b[1;32m    944\u001b[0m     \u001b[39m# Raise when data object is present and a vector can't matched\u001b[39;00m\n\u001b[1;32m    945\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(val, pd\u001b[39m.\u001b[39mSeries):\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `signal_mean_mean` for parameter `y`"
     ]
    }
   ],
   "source": [
    "\n",
    "plot_data(df = d1_cue_da_ds, title='downsampled data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(df = correct_down_sample, title='correct downsampled data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_ds_query = .query('day==1 & event==\"cue\" & sensor==\"DA\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error in down sampling\n",
    "* I made a mistake in when I introduced the downsampling for this data. I think I need to introduce it after grouping and processing right before training? The below is an interative process for finding the correct order of operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_update(df):\n",
    "    def flatten_df(df):\n",
    "        df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    def strip_cols(df):\n",
    "            df.columns = [col.rstrip('_') for col in df.columns]\n",
    "            return df\n",
    "        \n",
    "    group_by = ['time', 'sensor', 'day', 'event']\n",
    "    agg_dict = {'signal': ['mean', 'sem']}\n",
    "\n",
    "    grouped= (\n",
    "        df.groupby(by=group_by, as_index=False).agg(agg_dict)\n",
    "        .pipe(flatten_df)\n",
    "        .pipe(strip_cols)\n",
    "        .drop(columns = 'index') \n",
    "    )\n",
    "    return (grouped\n",
    "            # .query('day==1 & event==\"cue\" & sensor==\"DA\"')\n",
    "            # .groupby(by = ['time', ], as_index=True).agg({'signal_mean': ['mean', 'sem']})\n",
    "            # .pipe(flatten_df)\n",
    "            # .pipe(strip_cols)\n",
    "    )\n",
    "\n",
    "\n",
    "grouped_data_update = filter_data_update(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_cue_da = grouped_data_update.query('day==1 & event==\"cue\" & sensor==\"DA\"')\n",
    "day1_cue_da"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_update(df, title):\n",
    "    sns.lineplot(data=df, x='time', y='signal_mean',linewidth=0.2)\n",
    "    # change y axsis to be -2 to 2\n",
    "    plt.fill_between(df['time'], df['signal_mean'] - df['signal_sem'], df['signal_mean'] + df['signal_sem'], alpha=.2, color='black')\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title(title)\n",
    "plot_data_update(df = day1_cue_da, title='raw data updated filter')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I beleive the downsampling after the aggregated and melted dataframe is the problem. \n",
    "* possible soluton - convert time to timeseries in padas -> resample \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {'mouse_id':'first', \n",
    "            'day':'first',\n",
    "            'event': 'first',\n",
    "            'trial': 'first', \n",
    "            'sensor': 'first', \n",
    "            'signal': 'mean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_us = raw_data.assign(time =pd.to_timedelta(raw_data['time'], unit='seconds'))\n",
    "resample = raw_data_us.resample('100ms', on='time').agg(agg_dict)\n",
    "resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def agg_data(df):\n",
    "\n",
    "        def flatten_df(df):\n",
    "            df.columns = ['_'.join(col) for col in df.columns.values]\n",
    "        #     df = df.reset_index()\n",
    "            return df\n",
    "        return (\n",
    "                df\n",
    "                # .assign(time =pd.to_timedelta(df['time'], unit='seconds'))\n",
    "                # .set_index('time')\n",
    "                .groupby(by = ['mouse_id', 'day', 'time', 'event', 'trial', 'sensor'], as_index=False)\n",
    "                # .resample('100ms')\n",
    "                .mean()\n",
    "                # .pipe(flatten_df)\n",
    "                )\n",
    "resample = agg_data(raw_ds25)\n",
    "resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds25.sort_values(by=['mouse_id', 'day', 'event', 'trial', 'time', 'sensor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_and_ds(df):\n",
    "    return (\n",
    "        df\n",
    "        .sort_values(by=['mouse_id', 'day', 'event', 'trial', 'sensor'])\n",
    "        # .reset_index(drop=True)\n",
    "        [::2]\n",
    "    )\n",
    "sort_and_ds(raw_ds25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grouped_data_update' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d1_cue_da_ds \u001b[39m=\u001b[39m grouped_data_update\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39mday==1 & event==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcue\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m & sensor==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDA\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grouped_data_update' is not defined"
     ]
    }
   ],
   "source": [
    "d1_cue_da_ds = grouped_data_update.query('day==1 & event==\"cue\" & sensor==\"DA\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sensor</th>\n",
       "      <th>trial</th>\n",
       "      <th>mouse_id</th>\n",
       "      <th>day</th>\n",
       "      <th>event</th>\n",
       "      <th>signal_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454210</th>\n",
       "      <td>-24.931187</td>\n",
       "      <td>DA</td>\n",
       "      <td>0</td>\n",
       "      <td>142_237</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>0.198750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733710</th>\n",
       "      <td>-24.734577</td>\n",
       "      <td>DA</td>\n",
       "      <td>0</td>\n",
       "      <td>142_237</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>1.011394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013210</th>\n",
       "      <td>-24.537968</td>\n",
       "      <td>DA</td>\n",
       "      <td>0</td>\n",
       "      <td>142_237</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>0.345653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292710</th>\n",
       "      <td>-24.341358</td>\n",
       "      <td>DA</td>\n",
       "      <td>0</td>\n",
       "      <td>142_237</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>0.950242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572210</th>\n",
       "      <td>-24.144749</td>\n",
       "      <td>DA</td>\n",
       "      <td>0</td>\n",
       "      <td>142_237</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>-1.777425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287631594</th>\n",
       "      <td>19.195868</td>\n",
       "      <td>DA</td>\n",
       "      <td>28</td>\n",
       "      <td>313_255</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>0.079195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288911094</th>\n",
       "      <td>19.392477</td>\n",
       "      <td>DA</td>\n",
       "      <td>28</td>\n",
       "      <td>313_255</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>-0.590885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290190594</th>\n",
       "      <td>19.589087</td>\n",
       "      <td>DA</td>\n",
       "      <td>28</td>\n",
       "      <td>313_255</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>-0.307998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291470094</th>\n",
       "      <td>19.785696</td>\n",
       "      <td>DA</td>\n",
       "      <td>28</td>\n",
       "      <td>313_255</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>-0.901103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292749594</th>\n",
       "      <td>19.982306</td>\n",
       "      <td>DA</td>\n",
       "      <td>28</td>\n",
       "      <td>313_255</td>\n",
       "      <td>1</td>\n",
       "      <td>cue</td>\n",
       "      <td>-0.038883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92693 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                time sensor  trial mouse_id  day event  signal_mean\n",
       "454210    -24.931187     DA      0  142_237    1   cue     0.198750\n",
       "1733710   -24.734577     DA      0  142_237    1   cue     1.011394\n",
       "3013210   -24.537968     DA      0  142_237    1   cue     0.345653\n",
       "4292710   -24.341358     DA      0  142_237    1   cue     0.950242\n",
       "5572210   -24.144749     DA      0  142_237    1   cue    -1.777425\n",
       "...              ...    ...    ...      ...  ...   ...          ...\n",
       "287631594  19.195868     DA     28  313_255    1   cue     0.079195\n",
       "288911094  19.392477     DA     28  313_255    1   cue    -0.590885\n",
       "290190594  19.589087     DA     28  313_255    1   cue    -0.307998\n",
       "291470094  19.785696     DA     28  313_255    1   cue    -0.901103\n",
       "292749594  19.982306     DA     28  313_255    1   cue    -0.038883\n",
       "\n",
       "[92693 rows x 7 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1_cue_da_ds.group_by()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guppy",
   "language": "python",
   "name": "guppy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
