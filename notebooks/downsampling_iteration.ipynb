{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating downsampling procedure iteratively"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code in this notebook is to validate data preprocessing and downsampling before before incorporating into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from src.utilities.pandas_helpers import flatten_dataframe, strip_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, title):\n",
    "    sns.lineplot(data=df, x='time', y='signal',linewidth=0.2)\n",
    "    # change y axsis to be -2 to 2\n",
    "    # plt.fill_between(df['time'], df['signal'] - df['signal_sem'], df['signal_mean'] + df['signal_sem'], alpha=.2, color='black')\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title(title)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = '/projects/p31961/gaby_data/aggregated_data/aggregated_data.parquet.gzp'\n",
    "raw_data = pd.read_parquet(RAW_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### missing values in aggreated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = raw_data.head()\n",
    "test_df\n",
    "\n",
    "def tweak_name(df):\n",
    "    return (\n",
    "        df\n",
    "        .assign(signal_mean=df['signal'].mean())\n",
    "        .rename(columns = {'signal_mean': 'RENAME'}))\n",
    "tweak_df = tweak_name(test_df)\n",
    "tweak_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_vals = raw_data[raw_data.isna().any(axis=1)]\n",
    "group_by = ['mouse_id', 'trial',  'day', 'event', 'sensor']\n",
    "nan_vals.groupby(by = group_by, as_index=False).count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function to organize and downsample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_data(df, group_by_cols, agg_dict, ignore_for_sorting, downsample_rate):\n",
    "    sort_by_list = [col for col in group_by_cols if col != ignore_for_sorting]\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .dropna(axis = 0, how = 'any') # drop any rows with nans\n",
    "        .groupby(by=group_by_cols, as_index=False).agg(agg_dict)\n",
    "        .pipe(flatten_dataframe) # flatten the multi-index\n",
    "        .pipe(strip_columns) # fixes the column names by stripping _\n",
    "        .drop(columns = 'index') # drop the index column\n",
    "        # sort by everything but time and signal columns, \n",
    "        # by default puts time column in the correct orientation for downsampling\n",
    "        .sort_values(by = sort_by_list)\n",
    "        .rename(columns = {'signal_mean':'signal'}) # rename signal_mean to signal\n",
    "        [::downsample_rate] # downsample by saving every 100th row\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_list = ['time', 'sensor', 'trial', 'mouse_id', 'day', 'event'] # columns to group by\n",
    "agg_dict = {'signal': ['mean']} # columns are aggregated to the mean and sem signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = down_sample_data(df = raw_data, \n",
    "                               group_by_cols=group_by_list, \n",
    "                               agg_dict = agg_dict,\n",
    "                               ignore_for_sorting = 'time',\n",
    "                               downsample_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same process for raw data without downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to query raw data\n",
    "def agg_data_no_downsample(df, group_by_cols, agg_dict,):\n",
    "    # sort_by = [col for col in group_by_cols if col != ignore_for_sorting]\n",
    "\n",
    "    return (\n",
    "        df\n",
    "        .dropna(axis = 0, how = 'any') # drop any rows with nans\n",
    "        .groupby(by=group_by_cols, as_index=False).agg(agg_dict)\n",
    "        .pipe(flatten_dataframe) # flatten the multi-index\n",
    "        .pipe(strip_columns) # fixes the column names by stripping _\n",
    "        .drop(columns = 'index') # drop the index column\n",
    "        # sort by everything but time and signal columns, \n",
    "        # by default puts time column in the correct orientation for downsampling\n",
    "        .sort_values(by = [col for col in group_by_cols if col != 'time'])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_raw_data = agg_data_no_downsample(df = raw_data,\n",
    "                                          group_by_cols = group_by_list, \n",
    "                                          agg_dict = agg_dict\n",
    "                                        )\n",
    "                                        #    ignore_for_sorting='time', \n",
    "                               "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query for day 1, cue, dopamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_cue_dopamine_query = 'day==5 & event==\"cue\" & sensor==\"DA\" & trial == 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query downsampled data\n",
    "d1_cue_da_ds = downsampled.query(da1_cue_dopamine_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query raw data\n",
    "# d1_cue_raw_no_ds = grouped_raw_data.query(da1_cue_dopamine_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot a sample query to make sure data looks correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(d1_cue_da_ds, 'Downsampled DA signal for mouse 142_237 on day 1 during cue event')\n",
    "# plot_data(d1_cue_raw_no_ds, 'Raw DA signal for mouse 142_237 on day 1 during cue event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled.query('day==1 & event==\"cue\" & sensor==\"DA\" & trial == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dope (Python 311)",
   "language": "python",
   "name": "dope"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
