{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250.0, 'dev_f1_score': 1.0, 'test_f1_score': 0.4009433962264151}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score\n",
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "\n",
    "from src.data_processing.pipelines.ClassifierPipe import ClassifierPipe\n",
    "from src.utilities.os_helpers import set_up_directories, set_up_logger\n",
    "\n",
    "def process_data(data_path, experiment_dir):\n",
    "    processor_pipe = (ClassifierPipe(data_path)\n",
    "             .read_raw_data()\n",
    "             .calculate_max_min_signal()\n",
    "             .drop_features([\"event\", \"trial\"])\n",
    "             .split_data(test_size=0.2,\n",
    "                test_dev_size=0.5, \n",
    "                split_group = \"mouse_id\", \n",
    "                stratify_group = \"sex\", \n",
    "                target='action',\n",
    "                save_subject_ids=True,\n",
    "                path_to_save =os.path.dirname(experiment_dir))\n",
    "            .transform_data(numeric_target_dict={'avoid': 1, 'escape': 0})\n",
    "    )\n",
    "    return processor_pipe\n",
    "\n",
    "def grid_search(processor, model, experiment_dir, search_space):\n",
    "    grid = GridSearchCV(model, search_space, cv=5, scoring = 'f1')\n",
    "    grid.fit(processor.X_train, processor.y_train)\n",
    "    \n",
    "        # get best parameters\n",
    "    best_params = grid.best_params_\n",
    "    best_estimator = grid.best_estimator_\n",
    "    best_estimator.fit(processor.X_dev, processor.y_dev)\n",
    "    dev_prediction = best_estimator.predict(processor.X_dev)\n",
    "    test_prediction = best_estimator.predict(processor.X_test)\n",
    "    dev_score = f1_score(processor.y_dev, dev_prediction)\n",
    "    test_score = f1_score(processor.y_test, test_prediction)\n",
    "    \n",
    "\n",
    "    best_params[\"dev_f1_score\"] =  dev_score\n",
    "    best_params[\"test_f1_score\"] =  test_score\n",
    "    \n",
    "    for k,v in best_params.items():\n",
    "        if not isinstance(v, float):\n",
    "            best_params[k] = float(v)\n",
    "    \n",
    "    print(best_params)\n",
    "    with open(os.path.join(experiment_dir, 'grid_search_results.json'), 'w') as f:\n",
    "        json.dump(best_params, f, indent='auto')\n",
    "\n",
    "def main():\n",
    "    DATA_PATH = '/projects/p31961/gaby_data/aggregated_data/raw_data/datasets/raw_data_raw_data.parquet.gzip'\n",
    "    MAIN_DIR = '/projects/p31961/ENIGMA/results/experiments'\n",
    "    EXPERIMENT_NAME = \"xbg_trial_classifier_ray_tuner\"\n",
    "    EXPERIMENT_DIR = os.path.join(MAIN_DIR, EXPERIMENT_NAME)\n",
    "    set_up_directories(EXPERIMENT_DIR)\n",
    "    LOG_FILE_PATH = os.path.join(EXPERIMENT_DIR, f'{EXPERIMENT_NAME}.log')\n",
    "        \n",
    "    # set up logger and directories\n",
    "    set_up_logger(LOG_FILE_PATH)\n",
    "    \n",
    "    #EXPERIMENT\n",
    "    logging.info(f'Created new directories: {EXPERIMENT_DIR}')\n",
    "    logging.info(f'Starting experiment: {EXPERIMENT_NAME}')\n",
    "    \n",
    "    \n",
    "    SEARCH_SPACE = {\n",
    "    \"n_estimators\": np.arange(50, 500, 100)\n",
    "    \"learning_rate\": np.arange(0.01, 0.3, 0.05),\n",
    "    \"max_depth\": np.arange(3, 15, 2),\n",
    "    \"min_child_weight\": np.arange(1, 10, 1),\n",
    "    \"gamma\": np.arange(0, 5, 1),\n",
    "    \"booster\": ['gbtree', 'gblinear', 'dart'],\n",
    "    \"subsample\": np.arange(0, 1, 0.2),\n",
    "    \"reg_lambda\": np.arange(0, 5, 0.5)\n",
    "    \n",
    "    }\n",
    "    model = xgb.XGBClassifier(objective='binary:logistic')\n",
    "    logging.info('Model defined, preproessing data')\n",
    "    processor = process_data(DATA_PATH, EXPERIMENT_DIR)\n",
    "    logging.info('Data processed')\n",
    "    logging.info('Starting grid search')\n",
    "    grid_search(processor, model, EXPERIMENT_DIR, SEARCH_SPACE)\n",
    "    logging.info(f'Grid search complete: saved at {EXPERIMENT_DIR}')\n",
    "    \n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enigma_xgbuser",
   "language": "python",
   "name": "enigma_xgbuser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
